{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bangla Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import hog, local_binary_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    height = 32\n",
    "    width = 32\n",
    "    for file_name in os.listdir(path):\n",
    "        file_path = path + '/' + file_name\n",
    "        for img_name in os.listdir(file_path):\n",
    "            if not img_name.startswith('.'):\n",
    "                if img_name.endswith('.png'):\n",
    "                    img = cv2.imread(file_path + '/' + img_name)\n",
    "                    new_img = cv2.resize(img, (height, width))\n",
    "                    images.append(new_img)\n",
    "                    labels.append(file_name)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Load Extracted Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature(feature, name):\n",
    "    # saving all our feature vectors in pickled file\n",
    "    with open('cache/' + name + '.pkl', 'wb') as fp:\n",
    "        pickle.dump(csr_matrix(feature), fp)\n",
    "    \n",
    "    print(f'Feature saved with name cache/{name}.pkl')\n",
    "\n",
    "def load_feature(feature_name):\n",
    "    return pickle.load(open(feature_name, 'rb')).A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Load PCA fit components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pca(pca_data, name):\n",
    "    pickle.dump(pca_data, open('pca/' + name + '.pkl', 'wb'))\n",
    "    print(f'PCA data saved with name pca/{name}.pkl')\n",
    "    \n",
    "def load_pca(pca_name):\n",
    "    return pickle.load(open(pca_nam, 'rb')).A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Load Trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    filename = input('Enter model file name:')\n",
    "    pickle.dump(model, open('models/'+filename + '.pkl', 'wb'))\n",
    "    print(f'Successfully saved model in models/{filename}.pkl')\n",
    "\n",
    "def load_model(model_name):\n",
    "    return pickle.load(open(model_name, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog(images, name='hog', save=False):\n",
    "    cell_size = (4, 4)    # h x w in pixels\n",
    "    block_size = (2, 2)     # h x w in cells\n",
    "    nbins = 9\n",
    "    \n",
    "    # winSize is the size of the image cropped to an multiple of the cell size\n",
    "    # cell_size is the size of the cells of the img patch over which to calculate the histograms\n",
    "    # block_size is the number of cells which fit in the patch\n",
    "    hog_desc = cv2.HOGDescriptor(_winSize=(images[0].shape[1] // cell_size[1] * cell_size[1],\n",
    "                                              images[0].shape[0] // cell_size[0] * cell_size[0]),\n",
    "                                    _blockSize=(block_size[1] * cell_size[1],\n",
    "                                                block_size[0] * cell_size[0]),\n",
    "                                    _blockStride=(cell_size[1], cell_size[0]),\n",
    "                                    _cellSize=(cell_size[1], cell_size[0]),\n",
    "                                    _nbins=nbins)\n",
    "    \n",
    "    def get_image_hog(image):\n",
    "        # HOG feature\n",
    "        f = hog_desc.compute(image)\n",
    "        \n",
    "        res = np.array(f)\n",
    "        return res.flatten()\n",
    "    \n",
    "    # HOG for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        f = get_image_hog(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY))\n",
    "        features.append(f)\n",
    "    \n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Binary Pattern (LBP) Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lbp(images, name='lbp', save=False):\n",
    "    result = np.array([local_binary_pattern(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 10, 3).flatten() for img in images])\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sift(images, name='sift', save=False):\n",
    "    \n",
    "    # SIFT descriptor for 1 image\n",
    "    def get_image_sift(image, vector_size=15):\n",
    "        alg = cv2.xfeatures2d.SIFT_create()\n",
    "        kps = alg.detect(image, None)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        \n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 128\n",
    "        needed_size = (vector_size * 128)\n",
    "        if len(kps) == 0:\n",
    "            return np.zeros(needed_size)\n",
    "        \n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "            \n",
    "        return dsc\n",
    "    \n",
    "    # SIFT descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_sift(img)\n",
    "        features.append(dsc)\n",
    "\n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattened Image feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened(images, name='flatten', save=False):\n",
    "    \n",
    "    def get_image_flatten(image):\n",
    "        return cv2.cvtColor(image,  cv2.COLOR_RGB2GRAY).flatten()\n",
    "        \n",
    "        \n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_flatten(img)\n",
    "        features.append(dsc)\n",
    "\n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(features, horizontal=True):\n",
    "    \"\"\"\n",
    "    Array of features [f1, f2, f3] where each fi is a feature set \n",
    "    eg. f1=rgb_flat, f2=SIFT, etc.\n",
    "    \"\"\"\n",
    "    if horizontal:\n",
    "        return np.hstack(features)\n",
    "    else:\n",
    "        return np.vstack(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_features_minmax(train, test):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    norm_train = min_max_scaler.fit_transform(train)\n",
    "    norm_test = min_max_scaler.transform(test)\n",
    "    \n",
    "    return norm_train, norm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_features_zscore(train, test):\n",
    "    min_max_scaler = preprocessing.StandardScaler()\n",
    "    norm_train = min_max_scaler.fit_transform(train)\n",
    "    norm_test = min_max_scaler.transform(test)\n",
    "    \n",
    "    return norm_train, norm_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_x, train_y, model_name='NB', validation=None):\n",
    "    \"\"\"\n",
    "    Possible model names: ['RF', 'SVM', 'XGB', 'KNN']\n",
    "    default = 'NB'\n",
    "    \n",
    "    validation: (val_x, val_y) tupple for validation accuracy score.\n",
    "    \n",
    "    return: trained model\n",
    "    \"\"\"\n",
    "    model = None\n",
    "    if model_name == 'SVM':\n",
    "        model = svm.SVC(gamma='scale', probability=True)\n",
    "    elif model_name == 'XGB':\n",
    "        model = XGBClassifier(n_estimators=200, max_depth=5, n_jobs=2)\n",
    "#         model = XGBClassifier()\n",
    "    elif model_name == 'RF':\n",
    "        model = RandomForestClassifier(n_estimators=200, max_depth=10)\n",
    "    elif model_name == 'KNN':\n",
    "        model = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "    else:\n",
    "        model = GaussianNB()\n",
    "    \n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    if validation is not None:\n",
    "        y_hat = model.predict(validation[0])\n",
    "        acc = metrics.accuracy_score(validation[1], y_hat)\n",
    "        print(f\"Validation Accuracy in '{model_name}' = {acc}\")\n",
    "        cm = metrics.confusion_matrix(validation[1], y_hat)\n",
    "        print(cm)\n",
    "        recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "        precision = cm[0][0] / (cm[0][0] + cm[1][0])\n",
    "        f1 = 2*(precision*recall)/(precision+recall)\n",
    "        print(f\"Recall in '{model_name}' = {recall}\")\n",
    "        print(f\"Precision in '{model_name}' = {precision}\")\n",
    "        print(f\"F1 Score in '{model_name}' = {f1}\")\n",
    "               \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_x, full_data_y = read_images('BanglaLekha-Isolated/Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size :  (166105, 32, 32, 3) (166105,)\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset size : \", full_data_x.shape, full_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Image size:  (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"One Image size: \", full_data_x[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, val_imgs, train_y, val_y = train_test_split(full_data_x, full_data_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data : (132884, 32, 32, 3)        Label:  (132884,)\n",
      "Validation data : (33221, 32, 32, 3)    Label:  (33221,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data :\", train_imgs.shape, \"       Label: \", train_y.shape) \n",
    "print(\"Validation data :\", val_imgs.shape, \"   Label: \", val_y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save train, validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/train_imgs.npy', train_imgs)\n",
    "np.save('data/train_y.npy', train_y)\n",
    "np.save('data/val_imgs.npy', val_imgs)\n",
    "np.save('data/val_y.npy', val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.load('data/train_imgs.npy')\n",
    "train_y = np.load('data/train_y.npy')\n",
    "val_imgs = np.load('data/val_imgs.npy')\n",
    "val_y = np.load('data/val_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 32, 32, 3), (33221, 32, 32, 3), (132884,), (33221,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs.shape, val_imgs.shape, train_y.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,10))\n",
    "plt.imshow(train_imgs[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature saved with name cache/hog_train.pkl\n",
      "Feature saved with name cache/hog_val.pkl\n"
     ]
    }
   ],
   "source": [
    "hog_train = get_hog(train_imgs, name='hog_train', save=True)\n",
    "hog_val = get_hog(val_imgs, name='hog_val', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_train = load_feature('cache/hog_train.pkl')\n",
    "hog_val = load_feature('cache/hog_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 1764), (33221, 1764))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_train.shape, hog_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature saved with name cache/lbp_train.pkl\n",
      "Feature saved with name cache/lbp_val.pkl\n"
     ]
    }
   ],
   "source": [
    "lbp_train = get_lbp(train_imgs, name='lbp_train', save=True)\n",
    "lbp_val = get_lbp(val_imgs, name='lbp_val', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_train = load_feature('cache/lbp_train.pkl')\n",
    "lbp_val = load_feature('cache/lbp_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 1024), (33221, 1024))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbp_train.shape, lbp_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature saved with name cache/sift_train.pkl\n",
      "Feature saved with name cache/sift_val.pkl\n"
     ]
    }
   ],
   "source": [
    "sift_train = get_sift(train_imgs, name='sift_train', save=True)\n",
    "sift_val = get_sift(val_imgs, name='sift_val', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_train = load_feature('cache/sift_train.pkl')\n",
    "sift_val = load_feature('cache/sift_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_train.shape, sift_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattened image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature saved with name cache/flatten_train.pkl\n",
      "Feature saved with name cache/flatten_val.pkl\n"
     ]
    }
   ],
   "source": [
    "flatten_train = get_flattened(train_imgs, name='flatten_train', save=True)\n",
    "flatten_val = get_flattened(val_imgs, name='flatten_val', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_train = load_feature('cache/flatten_train.pkl')\n",
    "flatten_val = load_feature('cache/flatten_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 1024), (33221, 1024))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_train.shape, flatten_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Features by PCA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOG PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_hog_train, norm_hog_val = norm_features_minmax(hog_train, hog_val)\n",
    "norm_hog_train, norm_hog_val = norm_features_zscore(hog_train, hog_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca_hog_train = pca.fit_transform(norm_hog_train)\n",
    "pca_hog_val = pca.transform(norm_hog_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cache/pca_hog_train.npy', pca_hog_train)\n",
    "np.save('cache/pca_hog_val.npy', pca_hog_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_hog_train = np.load('cache/pca_hog_train.npy')\n",
    "pca_hog_val = np.load('cache/pca_hog_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 10), (33221, 10))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_hog_train.shape, pca_hog_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LBP PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_lbp_train, norm_lbp_val = norm_features_minmax(lbp_train, lbp_val)\n",
    "norm_lbp_train, norm_lbp_val = norm_features_zscore(lbp_train, lbp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca_lbp_train = pca.fit_transform(norm_lbp_train)\n",
    "pca_lbp_val = pca.transform(norm_lbp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cache/pca_lbp_train.npy', pca_lbp_train)\n",
    "np.save('cache/pca_lbp_val.npy', pca_lbp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lbp_train = np.load('cache/pca_lbp_train.npy')\n",
    "pca_lbp_val = np.load('cache/pca_lbp_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 10), (33221, 10))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lbp_train.shape, pca_lbp_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIFT PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_sift_train, norm_sift_val = norm_features_minmax(sift_train, sift_val)\n",
    "norm_sift_train, norm_sift_val = norm_features_zscore(sift_train, sift_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca_sift_train = pca.fit_transform(norm_sift_train)\n",
    "pca_sift_val = pca.transform(norm_sift_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cache/pca_sift_train.npy', pca_sift_train)\n",
    "np.save('cache/pca_sift_val.npy', pca_sift_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_sift_train = np.load('cache/pca_sift_train.npy')\n",
    "pca_sift_val = np.load('cache/pca_sift_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 5), (33221, 5))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_sift_train.shape, pca_sift_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_x, features_val_x, features_train_y, features_val_y = flatten_train, flatten_val, train_y, val_y\n",
    "features_train_x, features_train_y = shuffle(features_train_x, features_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy in 'RF' = 0.3317479907287559\n",
      "[[ 47   0   1 ...   0   0   0]\n",
      " [  2 183   7 ...   0   0   1]\n",
      " [  0   2 265 ...   0   0  11]\n",
      " ...\n",
      " [  2   0   1 ...   9   1   2]\n",
      " [  0   2  22 ...   0  92   3]\n",
      " [  0   0  44 ...   0   4 173]]\n",
      "Recall in 'RF' = 1.0\n",
      "Precision in 'RF' = 0.9591836734693877\n",
      "F1 Score in 'RF' = 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "model1 = train_model(np.array(features_train_x), features_train_y, model_name='RF', validation=(features_val_x, features_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = train_model(np.array(features_train_x), features_train_y, model_name='SVM', validation=(features_val_x, features_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = train_model(np.array(features_train_x), features_train_y, model_name='XGB', validation=(features_val_x, features_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = train_model(np.array(features_train_x), features_train_y,, model_name='KNN', validation=(features_val_x, features_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
